{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score, classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from seaborn import heatmap\n",
    "import yellowbrick\n",
    "from yellowbrick.classifier import ROCAUC\n",
    "from yellowbrick.classifier import ConfusionMatrix\n",
    "from yellowbrick.classifier import ClassPredictionError\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "%matplotlib inline\n",
    "import re\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from sacremoses import MosesDetokenizer\n",
    "from num2words import num2words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for cleaning text\n",
    "\n",
    "# REMOVED TAGS and STOPWORDS\n",
    "# REMOVED PUNCTUATION\n",
    "# LEMMATIZE\n",
    "# Used num2words module to CHANGE DIGITS INTO STRINGS\n",
    "\n",
    "def clean_text(text_raw):\n",
    "    text_ready = []\n",
    "    dt = MosesDetokenizer()\n",
    "    stops = stopwords.words('english')\n",
    "    lem = WordNetLemmatizer()\n",
    "\n",
    "    for t in text_raw:\n",
    "\n",
    "        cleaned = []\n",
    "        text = re.sub(r'[\\\\]',' \\\\ ', str(t))\n",
    "        text = re.sub(r'[\\d]', lambda x: num2words(x.group()), text)\n",
    "        text = re.sub(r'[^\\w\\s]','', text)\n",
    "        text = nltk.word_tokenize(text.lower())\n",
    "\n",
    "        for word in text:\n",
    "            word = word.strip()\n",
    "            if word not in stops:\n",
    "                cleaned.append(lem.lemmatize(word))\n",
    "        text_ready.append(dt.detokenize(cleaned, return_str=True))\n",
    "\n",
    "    return text_ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken (modified) from https://stackoverflow.com/questions/28200786/how-to-plot-scikit-learn-classification-report\n",
    "def plot_CR(prediction, ytest=y_test):\n",
    "    report_data = []\n",
    "    for label, metrics in classification_report(ytest, prediction, output_dict=True).items():\n",
    "        metrics['label'] = label\n",
    "        report_data.append(metrics)\n",
    "\n",
    "    report_df = pd.DataFrame(\n",
    "        report_data, \n",
    "        columns=['label', 'precision', 'recall', 'f1-score', 'support']\n",
    "    )\n",
    "\n",
    "    report_df['labelsupport'] = [f'{label} (n={support})' \n",
    "                                 for label, support in zip(report_df.label, report_df.support)]\n",
    "\n",
    "    # Plot the chart the same way, but use `labelsupport` as the x-axis.\n",
    "    report_df.plot(y=['precision', 'recall', 'f1-score'], x='labelsupport', kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open sample file\n",
    "\n",
    "with open('./2sample_50000_1.json', 'r', errors='ignore' ) as json_file: \n",
    "        sample = pd.read_json(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean and preprocess Sample using cleaning function -> Store in new Series in the Dataframe\n",
    "\n",
    "sample['clean_text'] = clean_text(sample['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.to_json(r'./clean_2sample_50000_1.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print first review from sample before and after cleaning \n",
    "\n",
    "print(sample['text'][0])\n",
    "print(sample['clean_text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting up Data into training and testing\n",
    "\n",
    "X_train_text, X_test_text,y_train,y_test=train_test_split(sample['clean_text'],\n",
    "                                              sample['stars'], train_size=0.6,\n",
    "                                              test_size=0.4,stratify=sample['stars'],\n",
    "                                              random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorizing using Count-Vectorizer - transforming into bigrams\n",
    "\n",
    "vect=CountVectorizer(ngram_range=(1,2),min_df=5).fit(X_train_text)\n",
    "X_train = vect.transform(X_train_text)\n",
    "X_test = vect.transform(X_test_text)\n",
    "\n",
    "feature_names=np.array(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check length of feature names and print first 20\n",
    "\n",
    "print(len(feature_names))\n",
    "print(feature_names[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifyVisualize(classifr, xtrain, ytrain, xtest, ytest):\n",
    "    # Visualizing ROCAUC Curves\n",
    "    ROCvisualizer = ROCAUC(classifr)\n",
    "\n",
    "    ROCvisualizer.fit(xtrain, ytrain)  # Fit the training data to the visualizer\n",
    "    ROCvisualizer.score(xtest, ytest)  # Evaluate the model on the test data\n",
    "    g = ROCvisualizer.poof()             # Draw/show/poof the data\n",
    "    \n",
    "    # Visualizing classification report\n",
    "    cr = yellowbrick.classifier.ClassificationReport(classifr, classes=[1, 2, 3, 4, 5])\n",
    "    cr.fit(xtrain, ytrain)\n",
    "    cr.score(xtest, ytest)\n",
    "    h = cr.poof()\n",
    "    \n",
    "    # Visualizing class prediction error\n",
    "    CPEvisualizer = ClassPredictionError(classifr, classes=[1, 2, 3, 4, 5])\n",
    "    # Fit the training data to the visualizer\n",
    "    CPEvisualizer.fit(xtrain, ytrain)\n",
    "\n",
    "    # Evaluate the model on the test data\n",
    "    CPEvisualizer.score(X_test, ytest)\n",
    "\n",
    "    # Draw visualization\n",
    "    cpe = CPEvisualizer.poof()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using LogisticRegression as Classifier - set to multinomial as it's multilabel classification\n",
    "# Using Gridsearch, to try different C scores\n",
    "\n",
    "LRclassifier = LogisticRegression(solver='newton-cg', multi_class='multinomial', C=0.1)\n",
    "\n",
    "\n",
    "gs = GridSearchCV(estimator=LRclassifier, param_grid={'C': [0.001, 0.01, 0.1, 1]}, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gs.best_params_) \n",
    "print(gs.best_score_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting Classifier and getting predictions\n",
    "\n",
    "LR_model = LRclassifier.fit(X_train, y_train)\n",
    "LR_predict = LR_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "classifyVisualize(classifr=LRclassifier, xtrain=X_train, ytrain=y_train, xtest=X_test, ytest=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Classification Report \n",
    "\n",
    "plot_CR(LR_predict)\n",
    "print(classification_report(LR_predict, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Dummy Classifier to compare results \n",
    "\n",
    "from sklearn.dummy import DummyClassifier \n",
    "dc = DummyClassifier(strategy='stratified')\n",
    "D_model = dc.fit(X_train, y_train)\n",
    "D_predict = D_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "classifyVisualize(classifr=dc, xtrain=X_train, ytrain=y_train, xtest=X_test, ytest=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plotting Classification Report \n",
    "\n",
    "plot_CR(D_predict)\n",
    "print(classification_report(D_predict, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install yellowbrick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using RandomForest Classifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "# Testing model\n",
    "rfcpredict = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifyVisualize(classifr=rfc, xtrain=X_train, ytrain=y_train, xtest=X_test, ytest=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_CR(rfcpredict)\n",
    "print(classification_report(rfcpredict, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Tfidf Vectorizer to compare\n",
    "\n",
    "tvect=TfidfVectorizer(ngram_range=(1,2),min_df=5).fit(X_train_text)\n",
    "X_trainT = tvect.transform(X_train_text)\n",
    "X_testT = tvect.transform(X_test_text)\n",
    "\n",
    "feature_namesT=np.array(tvect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifyVisualize(classifr=LRclassifier, xtrain=X_trainT, ytrain=y_train, xtest=X_testT, ytest=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Logistic Regression model with Tfidf\n",
    "\n",
    "LR_modelT = LRclassifier.fit(X_trainT, y_train)\n",
    "LR_predictT = LR_model.predict(X_testT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Classification Report \n",
    "\n",
    "plot_CR(LR_predictT)\n",
    "print(classification_report(LR_predictT, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing using OneVsRestClassifier( with MultinomialNB and TfidfVectorizer)\n",
    "\n",
    "classifyVisualize(classifr=OneVsRestClassifier(MultinomialNB(\n",
    "                    fit_prior=True, class_prior=None)),\n",
    "                  xtrain=X_trainT, ytrain=y_train, xtest=X_testT, ytest=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing using OneVsRestClassifier( with MultinomialNB and TfidfVectorizer)\n",
    "\n",
    "# Inspiration and code for pipeline parameters taken from amalgamation of StackOverflow articles\n",
    "NB_pipeline = Pipeline([\n",
    "                ('tfidf', TfidfVectorizer(stop_words=stop_words)),\n",
    "                ('clf', OneVsRestClassifier(MultinomialNB(\n",
    "                    fit_prior=True, class_prior=None))),\n",
    "            ])\n",
    "NB_pipeline.fit(X_train_text, y_train)\n",
    "NBprediction = NB_pipeline.predict(X_test_text)\n",
    "\n",
    "plot_CR(NBprediction)\n",
    "print(classification_report(NBprediction, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Testing using OneVsRestClassifier( with LinearSVC() and TfidfVectorizer)\n",
    "\n",
    "classifyVisualize(classifr=OneVsRestClassifier(LinearSVC(), n_jobs=1),\n",
    "                  xtrain=X_trainT, ytrain=y_train, xtest=X_testT, ytest=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Testing using OneVsRestClassifier( with LinearSVC() and TfidfVectorizer)\n",
    "\n",
    "# Inspiration and code for pipeline parameters taken from amalgamation of StackOverflow articles\n",
    "SVC_pipeline = Pipeline([\n",
    "                ('tfidf', TfidfVectorizer(stop_words=stop_words)),\n",
    "                ('clf', OneVsRestClassifier(LinearSVC(), n_jobs=1)),\n",
    "            ])\n",
    "\n",
    "SVC_pipeline.fit(X_train_text, y_train)\n",
    "# compute the testing accuracy\n",
    "SVCprediction = SVC_pipeline.predict(X_test_text)\n",
    "\n",
    "plot_CR(SVCprediction)\n",
    "print(classification_report(SVCprediction, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
